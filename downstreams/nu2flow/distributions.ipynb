{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T19:34:15.851798Z",
     "start_time": "2025-05-18T19:34:15.743465Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import vector\n",
    "from pathlib import Path\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from downstreams.plotting.kinematic_comparison import plot_kinematics_comparison"
   ],
   "id": "dd95519dae9f7116",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T19:34:16.099749Z",
     "start_time": "2025-05-18T19:34:15.989363Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def process_batch(batch):\n",
    "    data_ = {}\n",
    "    for label, group in [('predict', batch['predict']), ('target', batch['target'])]:\n",
    "        for key, tensor in group.items():\n",
    "            for i in range(tensor.shape[1]):\n",
    "                col_name = (label, f\"{key.replace('log_', '')}_{i}\")\n",
    "\n",
    "                if 'log_pt' in key:\n",
    "                    data_[col_name] = np.exp(tensor[:, i].numpy())\n",
    "                else:\n",
    "                    data_[col_name] = tensor[:, i].numpy()\n",
    "\n",
    "    # Create MultiIndex DataFrame\n",
    "    df = pd.DataFrame(data_)\n",
    "    df.columns = pd.MultiIndex.from_tuples(df.columns)\n",
    "    return df\n",
    "\n",
    "\n",
    "def extract_neutrinos(df, label):\n",
    "    # Stack pt, eta, phi, mass for neutrinos 0 and 1\n",
    "    pts = np.stack([df[(label, f\"pt_{i}\")].values for i in range(2)], axis=1)\n",
    "    etas = np.stack([df[(label, f\"eta_{i}\")].values for i in range(2)], axis=1)\n",
    "    phis = np.stack([df[(label, f\"phi_{i}\")].values for i in range(2)], axis=1)\n",
    "\n",
    "    # Now build the vector array (num_events, 2)\n",
    "    vecs = vector.array({\n",
    "        \"pt\": pts,\n",
    "        \"eta\": etas,\n",
    "        \"phi\": phis,\n",
    "        \"mass\": np.zeros_like(pts),\n",
    "    })\n",
    "    return vecs\n",
    "\n",
    "\n",
    "def extract_particles(df, prefix1, prefix2):\n",
    "    \"\"\"\n",
    "    Builds a vector array of shape (num_events, 2) by combining two particle sources.\n",
    "    Each is extracted using pt/eta/phi/mass or energy from the DataFrame.\n",
    "    \"\"\"\n",
    "\n",
    "    def get_components(prefix):\n",
    "        if f\"{prefix}/mass\" in df.columns:\n",
    "            return (\n",
    "                df[f\"{prefix}/pt\"].values,\n",
    "                df[f\"{prefix}/eta\"].values,\n",
    "                df[f\"{prefix}/phi\"].values,\n",
    "                df[f\"{prefix}/mass\"].values,\n",
    "                \"mass\"\n",
    "            )\n",
    "        elif f\"{prefix}/energy\" in df.columns:\n",
    "            return (\n",
    "                df[f\"{prefix}/pt\"].values,\n",
    "                df[f\"{prefix}/eta\"].values,\n",
    "                df[f\"{prefix}/phi\"].values,\n",
    "                df[f\"{prefix}/energy\"].values,\n",
    "                \"energy\"\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"Missing mass or energy columns for prefix: {prefix}\")\n",
    "\n",
    "    # Get components and type for each particle\n",
    "    pt1, eta1, phi1, m1, type1 = get_components(prefix1)\n",
    "    pt2, eta2, phi2, m2, type2 = get_components(prefix2)\n",
    "\n",
    "    if type1 != type2:\n",
    "        raise ValueError(f\"Inconsistent 4-momentum components: {prefix1} uses {type1}, {prefix2} uses {type2}\")\n",
    "\n",
    "    return vector.arr({\n",
    "        \"pt\": np.stack([pt1, pt2], axis=1),\n",
    "        \"eta\": np.stack([eta1, eta2], axis=1),\n",
    "        \"phi\": np.stack([phi1, phi2], axis=1),\n",
    "        type1: np.stack([m1, m2], axis=1),\n",
    "    })\n",
    "\n",
    "\n",
    "def process_data(data, baseline_selections):\n",
    "    dfs = []\n",
    "    for batch in data:\n",
    "        # Process the batch\n",
    "        df_ = process_batch(batch['neutrinos'])\n",
    "        df_extra = {extra_key.replace('EXTRA/', ''): batch[extra_key] for extra_key in batch.keys() if\n",
    "                    'EXTRA/' in extra_key}\n",
    "        df_extra = pd.DataFrame(df_extra)\n",
    "\n",
    "        dfs.append(pd.concat([df_, df_extra], axis=1))\n",
    "\n",
    "    final_df = pd.concat(dfs, ignore_index=True)\n",
    "    final_df = final_df.query(baseline_selections)\n",
    "\n",
    "    nu_pred = extract_neutrinos(final_df, \"predict\")\n",
    "    nu_truth = extract_neutrinos(final_df, \"target\")\n",
    "\n",
    "    particles = {\n",
    "        \"predict\": nu_pred,\n",
    "        \"target\": nu_truth,\n",
    "\n",
    "        \"b\": extract_particles(final_df, \"t1/b\", \"t2/b\"),\n",
    "        \"lepton\": extract_particles(final_df, \"t1/l\", \"t2/l\"),\n",
    "        \"truth_top\": extract_particles(final_df, \"truth_t1/t\", \"truth_t2/t\"),\n",
    "        \"truth_W\": extract_particles(final_df, \"truth_t1/W\", \"truth_t2/W\"),\n",
    "        \"truth_lepton\": extract_particles(final_df, \"truth_t1/l\", \"truth_t2/l\"),\n",
    "    }\n",
    "\n",
    "    # calculate reconstructed W\n",
    "    particles['W'] = particles['lepton'] + particles['predict']\n",
    "    # calculate reconstructed top\n",
    "    particles['top'] = particles['b'] + particles['W']\n",
    "    # replace the truth W with reconstructed lepton + truth neutrino\n",
    "    particles['plot_truth_W'] = particles['lepton'] + particles['target']\n",
    "    # replace the truth Top with reconstructed lepton + truth neutrino + b\n",
    "    particles['plot_truth_top'] = particles['b'] + particles['lepton'] + particles['target']\n",
    "\n",
    "    return particles"
   ],
   "id": "8b3b221638eb2d7c",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T19:34:16.453495Z",
     "start_time": "2025-05-18T19:34:16.342377Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def preprocess(baseline_nu):\n",
    "    # calculate observables\n",
    "    def build_observables(top: vector.MomentumNumpy4D, lepton: vector.MomentumNumpy4D):\n",
    "        # ttÌ„ system\n",
    "        ttbar = top.sum(axis=1)\n",
    "\n",
    "        df = pd.DataFrame({\n",
    "            \"m_tt\": ttbar.mass,\n",
    "            \"pt_tt\": ttbar.pt,\n",
    "            \"y_tt\": ttbar.rapidity,\n",
    "            \"pt_t1\": getattr(top[:, 0], \"pt\"),\n",
    "            \"pt_t2\": getattr(top[:, 1], \"pt\"),\n",
    "            \"dphi_ll\": getattr(lepton[:, 0], \"deltaphi\")(lepton[:, 1]) / np.pi,\n",
    "        })\n",
    "\n",
    "        return df\n",
    "\n",
    "    df_truth = build_observables(baseline_nu[\"truth_top\"], baseline_nu[\"truth_lepton\"])\n",
    "    df_reco_truthnu = build_observables(baseline_nu[\"plot_truth_top\"], baseline_nu[\"lepton\"])\n",
    "    df_reco_prednu = build_observables(baseline_nu[\"top\"], baseline_nu[\"lepton\"])\n",
    "\n",
    "    # Rename columns to avoid collisions\n",
    "    df_truth = df_truth.add_suffix(\"_truth\")\n",
    "    df_reco_truthnu = df_reco_truthnu.add_suffix(\"_reco_truthnu\")\n",
    "    df_reco_prednu = df_reco_prednu.add_suffix(\"_reco_prednu\")\n",
    "\n",
    "    # Combine into one DataFrame (all same length, aligned row by row)\n",
    "    df_all = pd.concat([df_truth, df_reco_truthnu, df_reco_prednu], axis=1)\n",
    "\n",
    "    return df_all"
   ],
   "id": "3feaf3ce1187e0d4",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T19:34:17.023526Z",
     "start_time": "2025-05-18T19:34:16.811320Z"
    }
   },
   "cell_type": "code",
   "source": [
    "p_dir = Path(os.getcwd()) / \"aux\"\n",
    "\n",
    "# data =\n",
    "nu_pretrain = process_data(\n",
    "    torch.load(\"/Users/avencastmini/PycharmProjects/EveNet/workspace/test_data/nu2flow/prediction-mg5-300.pretrain.pt\"),\n",
    "    baseline_selections=\"(num_bjet == 2) and `t1/b/pt` > 0 and `t2/b/pt` > 0 and `t1/l/pt` > 0 and `t2/l/pt` > 0\"\n",
    ")\n",
    "\n",
    "nu_scratch = process_data(\n",
    "    torch.load(\"/Users/avencastmini/PycharmProjects/EveNet/workspace/test_data/nu2flow/prediction-mg5-300.pt\"),\n",
    "    baseline_selections=\"(num_bjet == 2) and `t1/b/pt` > 0 and `t2/b/pt` > 0 and `t1/l/pt` > 0 and `t2/l/pt` > 0\"\n",
    "    # baseline_selections=\"(num_bjet >= 0)\"\n",
    "    # baseline_selections=\"`t1/b/pt` > 25 and `t2/b/pt` > 25 and `t1/l/pt` > 15 and `t2/l/pt` > 15\",\n",
    ")\n",
    "\n",
    "print(\"Selected Events: \", len(nu_pretrain[\"predict\"]), len(nu_scratch[\"predict\"]))"
   ],
   "id": "c3515a04a09286b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Events:  26729 26729\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T19:34:18.996294Z",
     "start_time": "2025-05-18T19:34:17.375038Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Unfolding\n",
    "from unfolding.unfold import main, hist_setup\n",
    "from downstreams.plotting.unfolding import plot_block_response, plot_uncertainty_with_ratio\n",
    "\n",
    "bin_edges = hist_setup()\n",
    "\n",
    "processed_nu_pretrain = preprocess(nu_pretrain)\n",
    "processed_nu_scratch = preprocess(nu_scratch)\n",
    "\n",
    "df_unfolded_pretrain = main(df=processed_nu_pretrain)\n",
    "df_unfolded_scratch = main(df=processed_nu_scratch)"
   ],
   "id": "7107f9b15bc0f45d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: truthnu - Variable: dphi_ll - done\n",
      "Category: truthnu - Variable: pt_t1 - done\n",
      "Category: truthnu - Variable: pt_t2 - done\n",
      "Category: truthnu - Variable: pt_tt - done\n",
      "Category: truthnu - Variable: y_tt - done\n",
      "Category: prednu - Variable: dphi_ll - done\n",
      "Category: prednu - Variable: pt_t1 - done\n",
      "Category: prednu - Variable: pt_t2 - done\n",
      "Category: prednu - Variable: pt_tt - done\n",
      "Category: prednu - Variable: y_tt - done\n",
      "Category: truthnu - Variable: dphi_ll - done\n",
      "Category: truthnu - Variable: pt_t1 - done\n",
      "Category: truthnu - Variable: pt_t2 - done\n",
      "Category: truthnu - Variable: pt_tt - done\n",
      "Category: truthnu - Variable: y_tt - done\n",
      "Category: prednu - Variable: dphi_ll - done\n",
      "Category: prednu - Variable: pt_t1 - done\n",
      "Category: prednu - Variable: pt_t2 - done\n",
      "Category: prednu - Variable: pt_tt - done\n",
      "Category: prednu - Variable: y_tt - done\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T19:34:22.280183Z",
     "start_time": "2025-05-18T19:34:19.357426Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def build_16x16_response(\n",
    "        df,\n",
    "        mtt_truth_col,\n",
    "        mtt_reco_col,\n",
    "        var_truth_col,\n",
    "        var_reco_col,\n",
    "        mtt_bins,\n",
    "        var_bins\n",
    "):\n",
    "    nbins = len(var_bins) - 1\n",
    "    response = np.zeros((nbins * nbins, nbins * nbins))\n",
    "\n",
    "    for i in range(nbins):  # reco mtt bin\n",
    "        reco_mask = (df[mtt_reco_col] >= mtt_bins[i]) & (df[mtt_reco_col] < mtt_bins[i + 1])\n",
    "        for j in range(nbins):  # truth mtt bin\n",
    "            truth_mask = (df[mtt_truth_col] >= mtt_bins[j]) & (df[mtt_truth_col] < mtt_bins[j + 1])\n",
    "            mask = reco_mask & truth_mask\n",
    "            df_sel = df[mask]\n",
    "\n",
    "            h2d, _, _ = np.histogram2d(\n",
    "                df_sel[var_reco_col],\n",
    "                df_sel[var_truth_col],\n",
    "                bins=[var_bins, var_bins]\n",
    "            )\n",
    "\n",
    "            row_start = i * nbins\n",
    "            col_start = j * nbins\n",
    "            response[row_start:row_start + nbins, col_start:col_start + nbins] = h2d\n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "# Define bin edges\n",
    "bins_mtt = bin_edges[\"m_tt\"]\n",
    "mtt_labels = [\n",
    "    r\"$m_{t\\bar{t}} < 400$\",\n",
    "    r\"$400 < m_{t\\bar{t}} < 500$\",\n",
    "    r\"$500 < m_{t\\bar{t}} < 800$\",\n",
    "    r\"$m_{t\\bar{t}} \\geq 800$\"\n",
    "]\n",
    "common_labels = {\n",
    "    \"dphi_ll\": {\n",
    "        \"name\": r\"$\\Delta\\phi(\\ell^+,\\ell^-) / \\pi$ [rad/$\\pi$]\",\n",
    "        \"bins\": bin_edges[\"dphi_ll\"],\n",
    "        \"truth_col\": \"dphi_ll_truth\",\n",
    "        \"labels\": [\"0â€“0.25\", \"0.25â€“0.5\", \"0.5â€“0.75\", \"0.75â€“1.0\"]\n",
    "    },\n",
    "    \"pt_t1\": {\n",
    "        \"name\": r\"$p_T^t$ [GeV]\",\n",
    "        \"bins\": bin_edges[\"pt_t1\"],\n",
    "        \"truth_col\": \"pt_t1_truth\",\n",
    "        \"labels\": [\"<75\", \"75â€“125\", \"125â€“175\", \"â‰¥175\"]\n",
    "    },\n",
    "    \"pt_tt\": {\n",
    "        \"name\": r\"$p_{T}^{t\\bar{t}}$ [GeV]\",\n",
    "        \"bins\": bin_edges[\"pt_tt\"],\n",
    "        \"truth_col\": \"pt_tt_truth\",\n",
    "        \"labels\": [\"<70\", \"70â€“140\", \"140â€“200\", \"â‰¥200\"]\n",
    "    },\n",
    "    \"y_tt\": {\n",
    "        \"name\": r\"$y_{t\\bar{t}}$\",\n",
    "        \"bins\": bin_edges[\"y_tt\"],\n",
    "        \"truth_col\": \"y_tt_truth\",\n",
    "        \"labels\": [\"<â€“1\", \"â€“1â€“0\", \"0â€“1\", \">1\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "for scenario, s_name in zip([\"reco_truthnu\", \"reco_prednu\"], [\"Truth_Nu\", \"Pred_Nu\"]):\n",
    "    variable_configs = [\n",
    "        {\n",
    "            \"reco_col\": f\"dphi_ll_{scenario}\",\n",
    "            **common_labels[\"dphi_ll\"],\n",
    "        },\n",
    "        {\n",
    "            \"reco_col\": f\"pt_t1_{scenario}\",\n",
    "            **common_labels[\"pt_t1\"],\n",
    "        },\n",
    "        {\n",
    "            \"reco_col\": f\"pt_tt_{scenario}\",\n",
    "            **common_labels[\"pt_tt\"],\n",
    "        },\n",
    "        {\n",
    "            \"reco_col\": f\"y_tt_{scenario}\",\n",
    "            **common_labels[\"y_tt\"],\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # Build and plot all variables\n",
    "    for df_plot, tag in zip([\n",
    "        processed_nu_pretrain,\n",
    "        processed_nu_scratch\n",
    "    ], [\n",
    "        'pretrain',\n",
    "        'scratch'\n",
    "    ]):\n",
    "        for var in variable_configs:\n",
    "            response = build_16x16_response(\n",
    "                df_plot,\n",
    "                mtt_truth_col=\"m_tt_truth\",\n",
    "                mtt_reco_col=\"m_tt_reco_prednu\",\n",
    "                var_truth_col=var[\"truth_col\"],\n",
    "                var_reco_col=var[\"reco_col\"],\n",
    "                mtt_bins=bins_mtt,\n",
    "                var_bins=var[\"bins\"]\n",
    "            )\n",
    "\n",
    "            plot_block_response(\n",
    "                response,\n",
    "                title=f\"EveNet: {s_name}\",\n",
    "                var_labels=var[\"labels\"],\n",
    "                mtt_labels=mtt_labels,\n",
    "                xlabel=f\"Detector-level {var['name']}\",\n",
    "                ylabel=f\"Parton-level {var['name']}\",\n",
    "                p_dir=p_dir,\n",
    "                save_name=f\"{s_name}_{var['truth_col'].replace('_truth', '')}.{tag}.pdf\"\n",
    "            )\n",
    "\n",
    "columns = list(range(16))\n",
    "paper_results = {\n",
    "    \"y_tt\": pd.DataFrame({\n",
    "        \"nu-weighting\": [2.9, 3.2, 3.0, 2.6, 2.9, 3.4, 3.1, 2.6, 2.7, 2.8, 2.9, 2.6, 2.4, 2.5, 2.6, 2.7],\n",
    "        \"Ellipse\": [3.5, 3.6, 3.2, 2.4, 2.2, 3.6, 3.5, 3.1, 3.6, 3.8, 4.1, 3.5, 3.1, 3.4, 3.6, 3.6],\n",
    "        \"nu2-flows\": [1.8, 1.9, 1.9, 1.8, 1.9, 2.1, 1.9, 1.8, 1.8, 1.8, 1.8, 1.7, 1.6, 1.6, 1.6, 1.7],\n",
    "        \"nu2-flows-pythia8\": [1.9, 1.9, 1.9, 1.8, 1.9, 2.1, 2.0, 1.8, 1.8, 1.8, 1.8, 1.7, 1.7, 1.6, 1.7, 1.8]\n",
    "    }, index=columns),\n",
    "    \"pt_tt\": pd.DataFrame({\n",
    "        \"nu-weighting\": [3.5, 2.6, 1.6, 2.1, 3.4, 3.0, 2.4, 2.3, 2.5, 2.7, 2.5, 2.2, 2.1, 2.2, 2.2, 2.3],\n",
    "        \"Ellipse\": [7.6, 5.3, 2.2, 3.7, 7.3, 5.7, 4.3, 4.1, 4.0, 4.7, 4.4, 3.8, 3.6, 3.3, 3.5, 3.8],\n",
    "        \"nu2-flows\": [1.9, 1.6, 1.2, 1.4, 2.0, 1.7, 1.5, 1.5, 1.6, 1.6, 1.6, 1.5, 1.5, 1.5, 1.5, 1.5],\n",
    "        \"nu2-flows-pythia8\": [2.0, 1.6, 1.2, 1.4, 2.0, 1.7, 1.5, 1.5, 1.7, 1.6, 1.6, 1.5, 1.5, 1.5, 1.5, 1.5]\n",
    "    }, index=columns),\n",
    "    \"pt_t1\": pd.DataFrame({\n",
    "        \"nu-weighting\": [3.1, 2.3, 1.7, 2.5, 3.2, 3.2, 2.8, 2.9, 2.8, 2.9, 2.9, 2.3, 2.2, 2.2, 2.3, 2.4],\n",
    "        \"Ellipse\": [4.8, 3.1, 2.5, 3.8, 4.9, 4.9, 3.8, 4.3, 4.0, 4.4, 4.9, 3.0, 3.5, 3.7, 3.6, 3.4],\n",
    "        \"nu2-flows\": [2.2, 1.9, 1.8, 2.1, 2.5, 2.4, 2.0, 2.2, 2.1, 2.0, 2.0, 1.7, 1.9, 1.9, 1.7, 1.6],\n",
    "        \"nu2-flows-pythia8\": [2.3, 1.9, 1.9, 2.2, 2.5, 2.4, 2.0, 2.3, 2.2, 2.1, 2.0, 1.7, 2.0, 2.0, 1.7, 1.6]\n",
    "    }, index=columns),\n",
    "    \"dphi_ll\": pd.DataFrame({\n",
    "        \"nu-weighting\": [2.0, 2.0, 1.5, 1.4, 1.9, 2.1, 2.0, 1.9, 1.9, 2.0, 2.2, 2.2, 2.0, 1.5, 1.6, 1.9],\n",
    "        \"Ellipse\": [2.2, 2.1, 1.5, 1.3, 1.8, 2.3, 2.4, 2.3, 2.3, 2.5, 2.8, 2.4, 1.7, 1.9, 2.4, 2.6],\n",
    "        \"nu2-flows\": [1.5, 1.5, 1.4, 1.4, 1.6, 1.6, 1.5, 1.5, 1.5, 1.5, 1.5, 1.3, 1.4, 1.5, 1.5, 1.5],\n",
    "        \"nu2-flows-pythia8\": [1.5, 1.5, 1.4, 1.4, 1.6, 1.6, 1.5, 1.5, 1.5, 1.5, 1.6, 1.5, 1.3, 1.4, 1.5, 1.5]\n",
    "    }, index=columns)\n",
    "}\n",
    "\n",
    "for var, var_cfg in common_labels.items():\n",
    "    truth_pretrain = df_unfolded_pretrain[f\"{var}_truthnu_unfold_error\"].values\n",
    "    truth_scratch = df_unfolded_scratch[f\"{var}_truthnu_unfold_error\"].values\n",
    "    methods = [\n",
    "        {\"name\": r\"EveNet - Scratch\", \"color\": \"red\",\n",
    "         \"data\": df_unfolded_scratch[f\"{var}_prednu_unfold_error\"] / truth_scratch},\n",
    "        {\"name\": r\"EveNet - Pretrain\", \"color\": \"green\",\n",
    "         \"data\": df_unfolded_pretrain[f\"{var}_prednu_unfold_error\"] / truth_pretrain},\n",
    "        {\"name\": r\"$\\nu^2$-Flows\", \"color\": \"blue\", \"data\": paper_results[var][\"nu2-flows\"].values},\n",
    "        # {\"name\": r\"$\\nu-2$-flow (P8)\", \"color\": \"green\", \"data\": paper_results[var][\"nu2-flows-pythia8\"].values},\n",
    "        {\"name\": r\"Ellipse\", \"color\": \"orange\", \"data\": paper_results[var][\"Ellipse\"].values},\n",
    "        {\"name\": r\"$\\nu$-weighting\", \"color\": \"purple\", \"data\": paper_results[var][\"nu-weighting\"].values}\n",
    "    ]\n",
    "\n",
    "    plot_uncertainty_with_ratio(\n",
    "        mtt_labels, var_cfg[\"labels\"], var_cfg['name'], methods,\n",
    "        ratio_baseline_name=r\"$\\nu^2$-Flows\",\n",
    "        p_dir=p_dir,\n",
    "        save_name=f\"unfolded_{var}.pdf\",\n",
    "        ratio_baseline_max=0.25,\n",
    "        ratio_baseline_min=-0.05,\n",
    "        ratio_y_label=r\"Improvement to $\\nu^2$-Flows\",\n",
    "    )\n",
    "\n"
   ],
   "id": "159ec061131998aa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_ratio, max_ratio -0.866666088889274 0.1608187236499177\n",
      "min_ratio, max_ratio -1.4499992750003625 0.1362996164048001\n",
      "min_ratio, max_ratio -2.9999984210534625 0.11212744687093991\n",
      "min_ratio, max_ratio -1.277777067901629 0.12310610985019961\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T19:34:30.863163Z",
     "start_time": "2025-05-18T19:34:22.642482Z"
    }
   },
   "cell_type": "code",
   "source": [
    "named_configs = {\n",
    "    \"neutrino\": {\n",
    "        \"variables\": [\"pt\", \"eta\", \"phi\"],\n",
    "        \"x_labels\": [r\"$p_T^{\\nu}$ [GeV]\", r\"$\\eta^{\\nu}$\", r\"$\\phi^{\\nu}$\"],\n",
    "        \"kin_range\": {\"pt\": (0, 350), \"eta\": (-np.pi * 1.5, np.pi * 1.5), \"phi\": (-np.pi, np.pi)},\n",
    "        # \"labels\": [r\"$\\nu$ from $(top^+)$\", r\"$\\nu$ from $(top^-)$\"],\n",
    "        \"labels\": [r\"$\\nu$ (scratch)\", r\"$\\nu$ (pretrain)\"],\n",
    "        \"colors\": ['#5bb5ac', '#de526c'],\n",
    "        \"columns\": ['predict', 'target'],\n",
    "        \"log_y\": [True, False, False],\n",
    "    },\n",
    "    \"top\": {\n",
    "        \"variables\": [\"pt\", \"eta\", \"phi\", \"mass\"],\n",
    "        \"x_labels\": [r\"$p_T^{t}$ [GeV]\", r\"$\\eta^{t}$\", r\"$\\phi^{t}$\", r\"$mass^{t}$ [GeV]\"],\n",
    "        \"kin_range\": {\"pt\": (0, 600), \"eta\": (-np.pi * 1.5, np.pi * 1.5), \"phi\": (-np.pi, np.pi), \"mass\": (100, 240)},\n",
    "        # \"labels\": [r\"$(top^+)$ \", r\"$(top^-)$\"],\n",
    "        \"labels\": [r\"$top$ (scratch)\", r\"$top$ (pretrain)\"],\n",
    "        \"colors\": ['#5bb5ac', '#de526c'],\n",
    "        \"columns\": ['top', 'plot_truth_top'],\n",
    "        \"log_y\": [True, False, False, False],\n",
    "    },\n",
    "    \"W\": {\n",
    "        \"variables\": [\"pt\", \"eta\", \"phi\", \"mass\"],\n",
    "        \"x_labels\": [r\"$p_T^{W}$ [GeV]\", r\"$\\eta^{W}$\", r\"$\\phi^{W}$\", r\"$mass^{W}$ [GeV]\"],\n",
    "        \"kin_range\": {\"pt\": (0, 350), \"eta\": (-np.pi * 1.5, np.pi * 1.5), \"phi\": (-np.pi, np.pi), \"mass\": (40, 120)},\n",
    "        # \"labels\": [r\"$(W^+)$\", r\"$(W^-)$\"],\n",
    "        \"labels\": [r\"$W$ (scratch)\", r\"$W$ (pretrain)\"],\n",
    "        \"colors\": ['#5bb5ac', '#de526c'],\n",
    "        \"columns\": ['W', 'plot_truth_W'],\n",
    "        \"log_y\": [True, False, False, False],\n",
    "    }\n",
    "}\n",
    "\n",
    "for particle, cfg in named_configs.items():\n",
    "\n",
    "    for i, var in enumerate(cfg[\"variables\"]):\n",
    "        fig, axs = plt.subplots(\n",
    "            3, 1, figsize=(10, 16),\n",
    "            gridspec_kw={'height_ratios': [3, 1, 2], 'hspace': 0.0},\n",
    "            sharex=True\n",
    "        )\n",
    "\n",
    "        plot_kinematics_comparison(\n",
    "            axs=axs,\n",
    "            # kin=[getattr(nu[cfg['columns'][0]][..., 0], var), getattr(nu[cfg['columns'][0]][..., 1], var)],\n",
    "            # truth_kin=[getattr(nu[cfg['columns'][1]][..., 0], var), getattr(nu[cfg['columns'][1]][..., 1], var)],\n",
    "            kin=[\n",
    "                np.concatenate([\n",
    "                    getattr(nu_scratch[cfg['columns'][0]][..., 0], var),\n",
    "                    getattr(nu_scratch[cfg['columns'][0]][..., 1], var)\n",
    "                ], axis=0),\n",
    "                np.concatenate([\n",
    "                    getattr(nu_pretrain[cfg['columns'][0]][..., 0], var),\n",
    "                    getattr(nu_pretrain[cfg['columns'][0]][..., 1], var)\n",
    "                ], axis=0)\n",
    "            ],\n",
    "            truth_kin=[\n",
    "                np.concatenate([\n",
    "                    getattr(nu_scratch[cfg['columns'][1]][..., 0], var),\n",
    "                    getattr(nu_scratch[cfg['columns'][1]][..., 1], var)\n",
    "                ], axis=0),\n",
    "                np.concatenate([\n",
    "                    getattr(nu_pretrain[cfg['columns'][1]][..., 0], var),\n",
    "                    getattr(nu_pretrain[cfg['columns'][1]][..., 1], var)\n",
    "                ], axis=0)\n",
    "            ],\n",
    "            bins=100,\n",
    "            kin_range=cfg[\"kin_range\"][var],\n",
    "            labels=cfg[\"labels\"],\n",
    "            colors=cfg[\"colors\"],\n",
    "            xlabel=cfg[\"x_labels\"][i],\n",
    "            normalize_col=cfg.get(\"normalize_col\", False),\n",
    "            log_z=cfg.get(\"log_z\", True),\n",
    "            log_y=cfg.get(\"log_y\", [False, False, False, False])[i],\n",
    "            c_percent=np.array([10, 100])\n",
    "        )\n",
    "\n",
    "        plt.tight_layout()\n",
    "        if not os.path.exists(p_dir / \"kinematics\"):\n",
    "            os.makedirs(p_dir / \"kinematics\")\n",
    "        plt.savefig(p_dir / \"kinematics\" / f\"{particle}_{var}.pdf\")\n",
    "        plt.close(fig)"
   ],
   "id": "6e664b18ea21d7cf",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/avencastmini/PycharmProjects/EveNet/downstreams/plotting/kinematic_comparison.py:51: UserWarning: Log scale: values of z <= 0 have been masked\n",
      "  ax.contourf(X, Y, Z, levels=levels, cmap=contour_colors[i], alpha=0.5, norm=mcolors.LogNorm())\n",
      "/Users/avencastmini/PycharmProjects/EveNet/downstreams/plotting/kinematic_comparison.py:51: UserWarning: Log scale: values of z <= 0 have been masked\n",
      "  ax.contourf(X, Y, Z, levels=levels, cmap=contour_colors[i], alpha=0.5, norm=mcolors.LogNorm())\n",
      "/Users/avencastmini/PycharmProjects/EveNet/downstreams/plotting/kinematic_comparison.py:51: UserWarning: Log scale: values of z <= 0 have been masked\n",
      "  ax.contourf(X, Y, Z, levels=levels, cmap=contour_colors[i], alpha=0.5, norm=mcolors.LogNorm())\n",
      "/Users/avencastmini/PycharmProjects/EveNet/downstreams/plotting/kinematic_comparison.py:51: UserWarning: Log scale: values of z <= 0 have been masked\n",
      "  ax.contourf(X, Y, Z, levels=levels, cmap=contour_colors[i], alpha=0.5, norm=mcolors.LogNorm())\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T19:34:31.226496Z",
     "start_time": "2025-05-18T19:34:31.224048Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "1defc50adbf2960c",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
