{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T20:06:23.000286Z",
     "start_time": "2025-04-30T20:06:21.604793Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import vector\n",
    "from pathlib import Path\n",
    "import os\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import matplotlib.pyplot as plt\n",
    "from downstreams.plotting.kinematic_comparison import plot_kinematics_comparison"
   ],
   "id": "dd95519dae9f7116",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T20:06:23.062588Z",
     "start_time": "2025-04-30T20:06:23.057941Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def process_batch(batch):\n",
    "    data_ = {}\n",
    "    for label, group in [('predict', batch['predict']), ('target', batch['target'])]:\n",
    "        for key, tensor in group.items():\n",
    "            for i in range(tensor.shape[1]):\n",
    "                col_name = (label, f\"{key.replace('log_', '')}_{i}\")\n",
    "\n",
    "                if 'log_pt' in key:\n",
    "                    data_[col_name] = np.exp(tensor[:, i].numpy())\n",
    "                else:\n",
    "                    data_[col_name] = tensor[:, i].numpy()\n",
    "\n",
    "    # Create MultiIndex DataFrame\n",
    "    df = pd.DataFrame(data_)\n",
    "    df.columns = pd.MultiIndex.from_tuples(df.columns)\n",
    "    return df\n",
    "\n",
    "\n",
    "def extract_neutrinos(df, label):\n",
    "    # Stack pt, eta, phi, mass for neutrinos 0 and 1\n",
    "    pts = np.stack([df[(label, f\"pt_{i}\")].values for i in range(2)], axis=1)\n",
    "    etas = np.stack([df[(label, f\"eta_{i}\")].values for i in range(2)], axis=1)\n",
    "    phis = np.stack([df[(label, f\"phi_{i}\")].values for i in range(2)], axis=1)\n",
    "\n",
    "    # Now build the vector array (num_events, 2)\n",
    "    vecs = vector.array({\n",
    "        \"pt\": pts,\n",
    "        \"eta\": etas,\n",
    "        \"phi\": phis,\n",
    "        \"mass\": np.zeros_like(pts),\n",
    "    })\n",
    "    return vecs\n",
    "\n",
    "\n",
    "def extract_particles(df, prefix1, prefix2):\n",
    "    \"\"\"\n",
    "    Builds a vector array of shape (num_events, 2) by combining two particle sources.\n",
    "    Each is extracted using pt/eta/phi/mass or energy from the DataFrame.\n",
    "    \"\"\"\n",
    "\n",
    "    def get_components(prefix):\n",
    "        if f\"{prefix}/mass\" in df.columns:\n",
    "            return (\n",
    "                df[f\"{prefix}/pt\"].values,\n",
    "                df[f\"{prefix}/eta\"].values,\n",
    "                df[f\"{prefix}/phi\"].values,\n",
    "                df[f\"{prefix}/mass\"].values,\n",
    "                \"mass\"\n",
    "            )\n",
    "        elif f\"{prefix}/energy\" in df.columns:\n",
    "            return (\n",
    "                df[f\"{prefix}/pt\"].values,\n",
    "                df[f\"{prefix}/eta\"].values,\n",
    "                df[f\"{prefix}/phi\"].values,\n",
    "                df[f\"{prefix}/energy\"].values,\n",
    "                \"energy\"\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"Missing mass or energy columns for prefix: {prefix}\")\n",
    "\n",
    "    # Get components and type for each particle\n",
    "    pt1, eta1, phi1, m1, type1 = get_components(prefix1)\n",
    "    pt2, eta2, phi2, m2, type2 = get_components(prefix2)\n",
    "\n",
    "    if type1 != type2:\n",
    "        raise ValueError(f\"Inconsistent 4-momentum components: {prefix1} uses {type1}, {prefix2} uses {type2}\")\n",
    "\n",
    "    return vector.arr({\n",
    "        \"pt\": np.stack([pt1, pt2], axis=1),\n",
    "        \"eta\": np.stack([eta1, eta2], axis=1),\n",
    "        \"phi\": np.stack([phi1, phi2], axis=1),\n",
    "        type1: np.stack([m1, m2], axis=1),\n",
    "    })\n",
    "\n",
    "\n",
    "def process_data(data, baseline_selections):\n",
    "    dfs = []\n",
    "    for batch in data:\n",
    "        # Process the batch\n",
    "        df_ = process_batch(batch['neutrinos'])\n",
    "        df_extra = {extra_key.replace('EXTRA/', ''): batch[extra_key] for extra_key in batch.keys() if\n",
    "                    'EXTRA/' in extra_key}\n",
    "        df_extra = pd.DataFrame(df_extra)\n",
    "\n",
    "        dfs.append(pd.concat([df_, df_extra], axis=1))\n",
    "\n",
    "    final_df = pd.concat(dfs, ignore_index=True)\n",
    "    final_df = final_df.query(baseline_selections)\n",
    "\n",
    "    nu_pred = extract_neutrinos(final_df, \"predict\")\n",
    "    nu_truth = extract_neutrinos(final_df, \"target\")\n",
    "\n",
    "    particles = {\n",
    "        \"predict\": nu_pred,\n",
    "        \"target\": nu_truth,\n",
    "\n",
    "        \"b\": extract_particles(final_df, \"t1/b\", \"t2/b\"),\n",
    "        \"lepton\": extract_particles(final_df, \"t1/l\", \"t2/l\"),\n",
    "        \"truth_top\": extract_particles(final_df, \"truth_t1/t\", \"truth_t2/t\"),\n",
    "        \"truth_W\": extract_particles(final_df, \"truth_t1/W\", \"truth_t2/W\"),\n",
    "        \"truth_lepton\": extract_particles(final_df, \"truth_t1/l\", \"truth_t2/l\"),\n",
    "    }\n",
    "\n",
    "    # calculate reconstructed W\n",
    "    particles['W'] = particles['lepton'] + particles['predict']\n",
    "    # calculate reconstructed top\n",
    "    particles['top'] = particles['b'] + particles['W']\n",
    "    # replace the truth W with reconstructed lepton + truth neutrino\n",
    "    particles['plot_truth_W'] = particles['lepton'] + particles['target']\n",
    "    # replace the truth Top with reconstructed lepton + truth neutrino + b\n",
    "    particles['plot_truth_top'] = particles['b'] + particles['lepton'] + particles['target']\n",
    "\n",
    "    return particles"
   ],
   "id": "8b3b221638eb2d7c",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T20:08:51.987963Z",
     "start_time": "2025-04-30T20:08:51.811581Z"
    }
   },
   "cell_type": "code",
   "source": [
    "p_dir = Path(os.getcwd()) / \"aux\"\n",
    "\n",
    "data = torch.load(\"/Users/avencastmini/PycharmProjects/EveNet/workspace/test_data/nu2flow/prediction-mg5-300.pt\")\n",
    "nu = process_data(\n",
    "    data,\n",
    "    baseline_selections=\"(num_bjet == 2) and `t1/b/pt` > 0 and `t2/b/pt` > 0 and `t1/l/pt` > 0 and `t2/l/pt` > 0\"\n",
    "    # baseline_selections=\"(num_bjet >= 0)\"\n",
    "    # baseline_selections=\"`t1/b/pt` > 25 and `t2/b/pt` > 25 and `t1/l/pt` > 15 and `t2/l/pt` > 15\",\n",
    ")\n",
    "\n",
    "print(len(nu[\"predict\"]))"
   ],
   "id": "c3515a04a09286b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26729\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T20:08:53.419830Z",
     "start_time": "2025-04-30T20:08:53.404388Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# calculate observables\n",
    "def build_observables(top: vector.MomentumNumpy4D, lepton: vector.MomentumNumpy4D):\n",
    "    # ttÌ„ system\n",
    "    ttbar = top.sum(axis=1)\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"m_tt\": ttbar.mass,\n",
    "        \"pt_tt\": ttbar.pt,\n",
    "        \"y_tt\": ttbar.rapidity,\n",
    "        \"pt_t1\": getattr(top[:, 0], \"pt\"),\n",
    "        \"pt_t2\": getattr(top[:, 1], \"pt\"),\n",
    "        \"dphi_ll\": getattr(lepton[:, 0], \"deltaphi\")(lepton[:, 1]) / np.pi,\n",
    "    })\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "df_truth = build_observables(nu[\"truth_top\"], nu[\"truth_lepton\"])\n",
    "df_reco_truthnu = build_observables(nu[\"plot_truth_top\"], nu[\"lepton\"])\n",
    "df_reco_prednu = build_observables(nu[\"top\"], nu[\"lepton\"])\n",
    "\n",
    "# Rename columns to avoid collisions\n",
    "df_truth = df_truth.add_suffix(\"_truth\")\n",
    "df_reco_truthnu = df_reco_truthnu.add_suffix(\"_reco_truthnu\")\n",
    "df_reco_prednu = df_reco_prednu.add_suffix(\"_reco_prednu\")\n",
    "\n",
    "# Combine into one DataFrame (all same length, aligned row by row)\n",
    "df_all = pd.concat([df_truth, df_reco_truthnu, df_reco_prednu], axis=1)"
   ],
   "id": "7ec92a0d84f118d7",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T20:08:55.115395Z",
     "start_time": "2025-04-30T20:08:54.015364Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Generalized response matrix builder\n",
    "def build_16x16_response(\n",
    "        df,\n",
    "        mtt_truth_col,\n",
    "        mtt_reco_col,\n",
    "        var_truth_col,\n",
    "        var_reco_col,\n",
    "        mtt_bins,\n",
    "        var_bins\n",
    "):\n",
    "    nbins = len(var_bins) - 1\n",
    "    response = np.zeros((nbins * nbins, nbins * nbins))\n",
    "\n",
    "    for i in range(nbins):  # reco mtt bin\n",
    "        reco_mask = (df[mtt_reco_col] >= mtt_bins[i]) & (df[mtt_reco_col] < mtt_bins[i + 1])\n",
    "        for j in range(nbins):  # truth mtt bin\n",
    "            truth_mask = (df[mtt_truth_col] >= mtt_bins[j]) & (df[mtt_truth_col] < mtt_bins[j + 1])\n",
    "            mask = reco_mask & truth_mask\n",
    "            df_sel = df[mask]\n",
    "\n",
    "            h2d, _, _ = np.histogram2d(\n",
    "                df_sel[var_reco_col],\n",
    "                df_sel[var_truth_col],\n",
    "                bins=[var_bins, var_bins]\n",
    "            )\n",
    "\n",
    "            row_start = i * nbins\n",
    "            col_start = j * nbins\n",
    "            response[row_start:row_start + nbins, col_start:col_start + nbins] = h2d\n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "# Generalized plotting function\n",
    "def plot_block_response(\n",
    "        response,\n",
    "        var_labels,\n",
    "        mtt_labels,\n",
    "        title=None,\n",
    "        xlabel=\"Truth $m_{tt}$ bin\",\n",
    "        ylabel=\"Reco variable bin\",\n",
    "        save_name=None,\n",
    "):\n",
    "    fig, ax = plt.subplots(figsize=(7, 7))\n",
    "\n",
    "    truth_sums = response.sum(axis=0, keepdims=True)\n",
    "    normed = 100 * np.divide(response, truth_sums, where=truth_sums != 0)\n",
    "\n",
    "    im = ax.imshow(normed, origin='lower', cmap='Blues', vmin=0, vmax=100)\n",
    "\n",
    "    # Annotate matrix\n",
    "    for i in range(normed.shape[0]):\n",
    "        for j in range(normed.shape[1]):\n",
    "            val = normed[i, j]\n",
    "            if val > 1:\n",
    "                ax.text(j, i, f\"{val:.0f}\", ha='center', va='center', fontsize=7)\n",
    "\n",
    "    # Grid lines\n",
    "    block_size = len(var_labels)\n",
    "    for i in range(0, response.shape[0], block_size):\n",
    "        ax.axhline(i - 0.5, color='k', linestyle='--', lw=1)\n",
    "        ax.axvline(i - 0.5, color='k', linestyle='--', lw=1)\n",
    "    ax.axhline(response.shape[0] - 0.5, color='k', linestyle='--', lw=1)\n",
    "    ax.axvline(response.shape[1] - 0.5, color='k', linestyle='--', lw=1)\n",
    "\n",
    "    # X ticks: 1 per mtt bin (block center)\n",
    "    xticks = [i * block_size + block_size / 2 - 0.5 for i in range(len(mtt_labels))]\n",
    "    ax.set_xticks(xticks)\n",
    "    ax.set_xticklabels(mtt_labels, fontsize=10)\n",
    "\n",
    "    # Y ticks: 1 per var bin\n",
    "    yticks = list(range(block_size * len(mtt_labels)))\n",
    "    ytick_labels = var_labels * len(mtt_labels)\n",
    "    ax.set_yticks(yticks)\n",
    "    ax.set_yticklabels(ytick_labels, fontsize=8)\n",
    "\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_title(title)\n",
    "\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\"right\", size=\"3%\", pad=0.05)  # shrink width to 3%\n",
    "    cbar = plt.colorbar(im, cax=cax)\n",
    "    cbar.set_label(\"Migration [%]\", fontsize=9)\n",
    "\n",
    "    # Trace fraction\n",
    "    trace = np.trace(response)\n",
    "    total = response.sum()\n",
    "    trace_frac = trace / total if total > 0 else 0\n",
    "    ax.text(1.0, 1.02, f\"trace fraction = {trace_frac:.2f}\", transform=ax.transAxes,\n",
    "            ha='right', fontsize=10)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    # plt.show()\n",
    "    if save_name:\n",
    "        if not os.path.exists(p_dir / \"response\"):\n",
    "            os.makedirs(p_dir / \"response\")\n",
    "        plt.savefig(p_dir / \"response\" / save_name)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# Define bin edges\n",
    "bins_mtt = [0, 400, 500, 800, np.inf]\n",
    "mtt_labels = [\n",
    "    r\"$m_{t\\bar{t}} < 400$\",\n",
    "    r\"$400 < m_{t\\bar{t}} < 500$\",\n",
    "    r\"$500 < m_{t\\bar{t}} < 800$\",\n",
    "    r\"$m_{t\\bar{t}} \\geq 800$\"\n",
    "]\n",
    "\n",
    "for scenario, s_name in zip([\"reco_truthnu\", \"reco_prednu\"], [\"Truth_Nu\", \"Pred_Nu\"]):\n",
    "    variable_configs = [\n",
    "        {\n",
    "            \"name\": r\"$\\Delta\\phi(\\ell^+,\\ell^-) / \\pi$ [rad/$\\pi$]\",\n",
    "            \"truth_col\": \"dphi_ll_truth\",\n",
    "            \"reco_col\": f\"dphi_ll_{scenario}\",\n",
    "            \"bins\": [0.0, 0.25, 0.5, 0.75, 1.0],\n",
    "            \"labels\": [\"0â€“0.25\", \"0.25â€“0.5\", \"0.5â€“0.75\", \"0.75â€“1.0\"]\n",
    "        },\n",
    "        {\n",
    "            \"name\": r\"$p_T^t$ [GeV]\",\n",
    "            \"truth_col\": \"pt_t1_truth\",\n",
    "            \"reco_col\": f\"pt_t1_{scenario}\",\n",
    "            \"bins\": [0, 75, 125, 175, np.inf],\n",
    "            \"labels\": [\"<75\", \"75â€“125\", \"125â€“175\", \"â‰¥175\"]\n",
    "        },\n",
    "        {\n",
    "            \"name\": r\"$p_{T}^{t\\bar{t}}$ [GeV]\",\n",
    "            \"truth_col\": \"pt_tt_truth\",\n",
    "            \"reco_col\": f\"pt_tt_{scenario}\",\n",
    "            \"bins\": [0, 70, 140, 200, np.inf],\n",
    "            \"labels\": [\"<70\", \"70â€“140\", \"140â€“200\", \"â‰¥200\"]\n",
    "        },\n",
    "        {\n",
    "            \"name\": r\"$y_{t\\bar{t}}$\",\n",
    "            \"truth_col\": \"y_tt_truth\",\n",
    "            \"reco_col\": f\"y_tt_{scenario}\",\n",
    "            \"bins\": [-np.inf, -1.0, 0.0, 1.0, np.inf],\n",
    "            \"labels\": [\"<â€“1\", \"â€“1â€“0\", \"0â€“1\", \">1\"]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # Build and plot all variables\n",
    "    for var in variable_configs:\n",
    "        response = build_16x16_response(\n",
    "            df_all,\n",
    "            mtt_truth_col=\"m_tt_truth\",\n",
    "            mtt_reco_col=\"m_tt_reco_prednu\",\n",
    "            var_truth_col=var[\"truth_col\"],\n",
    "            var_reco_col=var[\"reco_col\"],\n",
    "            mtt_bins=bins_mtt,\n",
    "            var_bins=var[\"bins\"]\n",
    "        )\n",
    "\n",
    "        plot_block_response(\n",
    "            response,\n",
    "            title=f\"EveNet: {s_name}\",\n",
    "            var_labels=var[\"labels\"],\n",
    "            mtt_labels=mtt_labels,\n",
    "            xlabel=f\"Detector-level {var['name']}\",\n",
    "            ylabel=f\"Parton-level {var['name']}\",\n",
    "            save_name=f\"{s_name}_{var['truth_col'].replace('_truth', '')}.pdf\"\n",
    "        )"
   ],
   "id": "159ec061131998aa",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T20:09:01.711740Z",
     "start_time": "2025-04-30T20:08:57.587664Z"
    }
   },
   "cell_type": "code",
   "source": [
    "named_configs = {\n",
    "    \"neutrino\": {\n",
    "        \"variables\": [\"pt\", \"eta\", \"phi\"],\n",
    "        \"x_labels\": [r\"$p_T^{\\nu}$ [GeV]\", r\"$\\eta^{\\nu}$\", r\"$\\phi^{\\nu}$\"],\n",
    "        \"kin_range\": {\"pt\": (0, 350), \"eta\": (-np.pi * 1.5, np.pi * 1.5), \"phi\": (-np.pi, np.pi)},\n",
    "        \"labels\": [r\"$\\nu$ from $(top^+)$\", r\"$\\nu$ from $(top^-)$\"],\n",
    "        \"colors\": ['#5bb5ac', '#de526c'],\n",
    "        \"columns\": ['predict', 'target'],\n",
    "        \"log_y\": [True, False, False],\n",
    "    },\n",
    "    \"top\": {\n",
    "        \"variables\": [\"pt\", \"eta\", \"phi\", \"mass\"],\n",
    "        \"x_labels\": [r\"$p_T^{t}$ [GeV]\", r\"$\\eta^{t}$\", r\"$\\phi^{t}$\", r\"$mass^{t}$ [GeV]\"],\n",
    "        \"kin_range\": {\"pt\": (0, 600), \"eta\": (-np.pi * 1.5, np.pi * 1.5), \"phi\": (-np.pi, np.pi), \"mass\": (100, 240)},\n",
    "        \"labels\": [r\"$(top^+)$\", r\"$(top^-)$\"],\n",
    "        \"colors\": ['#5bb5ac', '#de526c'],\n",
    "        \"columns\": ['top', 'plot_truth_top'],\n",
    "        \"log_y\": [True, False, False, False],\n",
    "    },\n",
    "    \"W\": {\n",
    "        \"variables\": [\"pt\", \"eta\", \"phi\", \"mass\"],\n",
    "        \"x_labels\": [r\"$p_T^{W}$ [GeV]\", r\"$\\eta^{W}$\", r\"$\\phi^{W}$\", r\"$mass^{W}$ [GeV]\"],\n",
    "        \"kin_range\": {\"pt\": (0, 350), \"eta\": (-np.pi * 1.5, np.pi * 1.5), \"phi\": (-np.pi, np.pi), \"mass\": (40, 120)},\n",
    "        \"labels\": [r\"$(W^+)$\", r\"$(W^-)$\"],\n",
    "        \"colors\": ['#5bb5ac', '#de526c'],\n",
    "        \"columns\": ['W', 'plot_truth_W'],\n",
    "        \"log_y\": [True, False, False, False],\n",
    "    }\n",
    "}\n",
    "\n",
    "for particle, cfg in named_configs.items():\n",
    "\n",
    "    for i, var in enumerate(cfg[\"variables\"]):\n",
    "        fig, axs = plt.subplots(\n",
    "            3, 1, figsize=(10, 16),\n",
    "            gridspec_kw={'height_ratios': [3, 1, 2], 'hspace': 0.0},\n",
    "            sharex=True\n",
    "        )\n",
    "\n",
    "        plot_kinematics_comparison(\n",
    "            axs=axs,\n",
    "            kin=[getattr(nu[cfg['columns'][0]][..., 0], var), getattr(nu[cfg['columns'][0]][..., 1], var)],\n",
    "            truth_kin=[getattr(nu[cfg['columns'][1]][..., 0], var), getattr(nu[cfg['columns'][1]][..., 1], var)],\n",
    "            # kin=[\n",
    "            #     np.concatenate([\n",
    "            #         getattr(nu[cfg['columns'][0]][..., 0], var),\n",
    "            #         getattr(nu[cfg['columns'][0]][..., 1], var)\n",
    "            #     ], axis=0),\n",
    "            #     np.concatenate([\n",
    "            #         getattr(nu[cfg['columns'][0]][..., 0], var),\n",
    "            #         getattr(nu[cfg['columns'][0]][..., 1], var)\n",
    "            #     ], axis=0)\n",
    "            # ],\n",
    "            # truth_kin=[\n",
    "            #     np.concatenate([\n",
    "            #         getattr(nu[cfg['columns'][1]][..., 0], var),\n",
    "            #         getattr(nu[cfg['columns'][1]][..., 1], var)\n",
    "            #     ], axis=0),\n",
    "            #     np.concatenate([\n",
    "            #         getattr(nu[cfg['columns'][1]][..., 0], var),\n",
    "            #         getattr(nu[cfg['columns'][1]][..., 1], var)\n",
    "            #     ], axis=0)\n",
    "            # ],\n",
    "            bins=100,\n",
    "            kin_range=cfg[\"kin_range\"][var],\n",
    "            labels=cfg[\"labels\"],\n",
    "            colors=cfg[\"colors\"],\n",
    "            xlabel=cfg[\"x_labels\"][i],\n",
    "            normalize_col=cfg.get(\"normalize_col\", False),\n",
    "            log_z=cfg.get(\"log_z\", True),\n",
    "            log_y=cfg.get(\"log_y\", [False, False, False, False])[i],\n",
    "            c_percent=np.array([10, 100])\n",
    "        )\n",
    "\n",
    "        plt.tight_layout()\n",
    "        if not os.path.exists(p_dir / \"kinematics\"):\n",
    "            os.makedirs(p_dir / \"kinematics\")\n",
    "        plt.savefig(p_dir / \"kinematics\" / f\"{particle}_{var}.pdf\")\n",
    "        plt.close(fig)"
   ],
   "id": "6e664b18ea21d7cf",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/avencastmini/PycharmProjects/EveNet/downstreams/plotting/kinematic_comparison.py:51: UserWarning: Log scale: values of z <= 0 have been masked\n",
      "  ax.contourf(X, Y, Z, levels=levels, cmap=contour_colors[i], alpha=0.5, norm=mcolors.LogNorm())\n",
      "/Users/avencastmini/PycharmProjects/EveNet/downstreams/plotting/kinematic_comparison.py:51: UserWarning: Log scale: values of z <= 0 have been masked\n",
      "  ax.contourf(X, Y, Z, levels=levels, cmap=contour_colors[i], alpha=0.5, norm=mcolors.LogNorm())\n",
      "/Users/avencastmini/PycharmProjects/EveNet/downstreams/plotting/kinematic_comparison.py:51: UserWarning: Log scale: values of z <= 0 have been masked\n",
      "  ax.contourf(X, Y, Z, levels=levels, cmap=contour_colors[i], alpha=0.5, norm=mcolors.LogNorm())\n",
      "/Users/avencastmini/PycharmProjects/EveNet/downstreams/plotting/kinematic_comparison.py:51: UserWarning: Log scale: values of z <= 0 have been masked\n",
      "  ax.contourf(X, Y, Z, levels=levels, cmap=contour_colors[i], alpha=0.5, norm=mcolors.LogNorm())\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T20:06:23.973523Z",
     "start_time": "2025-04-30T14:44:16.510593Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "c1399e6453c2ac58",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "da7240681e7775b6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f7839d253a4e5949"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
