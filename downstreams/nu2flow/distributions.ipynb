{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T17:59:14.519989Z",
     "start_time": "2025-05-01T17:59:13.244419Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import vector\n",
    "from pathlib import Path\n",
    "import os\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import matplotlib.pyplot as plt\n",
    "from downstreams.plotting.kinematic_comparison import plot_kinematics_comparison"
   ],
   "id": "dd95519dae9f7116",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T17:59:16.230349Z",
     "start_time": "2025-05-01T17:59:16.221045Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def process_batch(batch):\n",
    "    data_ = {}\n",
    "    for label, group in [('predict', batch['predict']), ('target', batch['target'])]:\n",
    "        for key, tensor in group.items():\n",
    "            for i in range(tensor.shape[1]):\n",
    "                col_name = (label, f\"{key.replace('log_', '')}_{i}\")\n",
    "\n",
    "                if 'log_pt' in key:\n",
    "                    data_[col_name] = np.exp(tensor[:, i].numpy())\n",
    "                else:\n",
    "                    data_[col_name] = tensor[:, i].numpy()\n",
    "\n",
    "    # Create MultiIndex DataFrame\n",
    "    df = pd.DataFrame(data_)\n",
    "    df.columns = pd.MultiIndex.from_tuples(df.columns)\n",
    "    return df\n",
    "\n",
    "\n",
    "def extract_neutrinos(df, label):\n",
    "    # Stack pt, eta, phi, mass for neutrinos 0 and 1\n",
    "    pts = np.stack([df[(label, f\"pt_{i}\")].values for i in range(2)], axis=1)\n",
    "    etas = np.stack([df[(label, f\"eta_{i}\")].values for i in range(2)], axis=1)\n",
    "    phis = np.stack([df[(label, f\"phi_{i}\")].values for i in range(2)], axis=1)\n",
    "\n",
    "    # Now build the vector array (num_events, 2)\n",
    "    vecs = vector.array({\n",
    "        \"pt\": pts,\n",
    "        \"eta\": etas,\n",
    "        \"phi\": phis,\n",
    "        \"mass\": np.zeros_like(pts),\n",
    "    })\n",
    "    return vecs\n",
    "\n",
    "\n",
    "def extract_particles(df, prefix1, prefix2):\n",
    "    \"\"\"\n",
    "    Builds a vector array of shape (num_events, 2) by combining two particle sources.\n",
    "    Each is extracted using pt/eta/phi/mass or energy from the DataFrame.\n",
    "    \"\"\"\n",
    "\n",
    "    def get_components(prefix):\n",
    "        if f\"{prefix}/mass\" in df.columns:\n",
    "            return (\n",
    "                df[f\"{prefix}/pt\"].values,\n",
    "                df[f\"{prefix}/eta\"].values,\n",
    "                df[f\"{prefix}/phi\"].values,\n",
    "                df[f\"{prefix}/mass\"].values,\n",
    "                \"mass\"\n",
    "            )\n",
    "        elif f\"{prefix}/energy\" in df.columns:\n",
    "            return (\n",
    "                df[f\"{prefix}/pt\"].values,\n",
    "                df[f\"{prefix}/eta\"].values,\n",
    "                df[f\"{prefix}/phi\"].values,\n",
    "                df[f\"{prefix}/energy\"].values,\n",
    "                \"energy\"\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"Missing mass or energy columns for prefix: {prefix}\")\n",
    "\n",
    "    # Get components and type for each particle\n",
    "    pt1, eta1, phi1, m1, type1 = get_components(prefix1)\n",
    "    pt2, eta2, phi2, m2, type2 = get_components(prefix2)\n",
    "\n",
    "    if type1 != type2:\n",
    "        raise ValueError(f\"Inconsistent 4-momentum components: {prefix1} uses {type1}, {prefix2} uses {type2}\")\n",
    "\n",
    "    return vector.arr({\n",
    "        \"pt\": np.stack([pt1, pt2], axis=1),\n",
    "        \"eta\": np.stack([eta1, eta2], axis=1),\n",
    "        \"phi\": np.stack([phi1, phi2], axis=1),\n",
    "        type1: np.stack([m1, m2], axis=1),\n",
    "    })\n",
    "\n",
    "\n",
    "def process_data(data, baseline_selections):\n",
    "    dfs = []\n",
    "    for batch in data:\n",
    "        # Process the batch\n",
    "        df_ = process_batch(batch['neutrinos'])\n",
    "        df_extra = {extra_key.replace('EXTRA/', ''): batch[extra_key] for extra_key in batch.keys() if\n",
    "                    'EXTRA/' in extra_key}\n",
    "        df_extra = pd.DataFrame(df_extra)\n",
    "\n",
    "        dfs.append(pd.concat([df_, df_extra], axis=1))\n",
    "\n",
    "    final_df = pd.concat(dfs, ignore_index=True)\n",
    "    final_df = final_df.query(baseline_selections)\n",
    "\n",
    "    nu_pred = extract_neutrinos(final_df, \"predict\")\n",
    "    nu_truth = extract_neutrinos(final_df, \"target\")\n",
    "\n",
    "    particles = {\n",
    "        \"predict\": nu_pred,\n",
    "        \"target\": nu_truth,\n",
    "\n",
    "        \"b\": extract_particles(final_df, \"t1/b\", \"t2/b\"),\n",
    "        \"lepton\": extract_particles(final_df, \"t1/l\", \"t2/l\"),\n",
    "        \"truth_top\": extract_particles(final_df, \"truth_t1/t\", \"truth_t2/t\"),\n",
    "        \"truth_W\": extract_particles(final_df, \"truth_t1/W\", \"truth_t2/W\"),\n",
    "        \"truth_lepton\": extract_particles(final_df, \"truth_t1/l\", \"truth_t2/l\"),\n",
    "    }\n",
    "\n",
    "    # calculate reconstructed W\n",
    "    particles['W'] = particles['lepton'] + particles['predict']\n",
    "    # calculate reconstructed top\n",
    "    particles['top'] = particles['b'] + particles['W']\n",
    "    # replace the truth W with reconstructed lepton + truth neutrino\n",
    "    particles['plot_truth_W'] = particles['lepton'] + particles['target']\n",
    "    # replace the truth Top with reconstructed lepton + truth neutrino + b\n",
    "    particles['plot_truth_top'] = particles['b'] + particles['lepton'] + particles['target']\n",
    "\n",
    "    return particles"
   ],
   "id": "8b3b221638eb2d7c",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T17:59:18.897865Z",
     "start_time": "2025-05-01T17:59:18.813230Z"
    }
   },
   "cell_type": "code",
   "source": [
    "p_dir = Path(os.getcwd()) / \"aux\"\n",
    "\n",
    "data = torch.load(\"/Users/avencastmini/PycharmProjects/EveNet/workspace/test_data/nu2flow/prediction-mg5-300.pt\")\n",
    "nu = process_data(\n",
    "    data,\n",
    "    baseline_selections=\"(num_bjet == 2) and `t1/b/pt` > 0 and `t2/b/pt` > 0 and `t1/l/pt` > 0 and `t2/l/pt` > 0\"\n",
    "    # baseline_selections=\"(num_bjet >= 0)\"\n",
    "    # baseline_selections=\"`t1/b/pt` > 25 and `t2/b/pt` > 25 and `t1/l/pt` > 15 and `t2/l/pt` > 15\",\n",
    ")\n",
    "\n",
    "print(\"Selected Events: \", len(nu[\"predict\"]))"
   ],
   "id": "c3515a04a09286b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Events:  26729\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T17:59:20.286404Z",
     "start_time": "2025-05-01T17:59:20.217183Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# calculate observables\n",
    "def build_observables(top: vector.MomentumNumpy4D, lepton: vector.MomentumNumpy4D):\n",
    "    # ttÌ„ system\n",
    "    ttbar = top.sum(axis=1)\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"m_tt\": ttbar.mass,\n",
    "        \"pt_tt\": ttbar.pt,\n",
    "        \"y_tt\": ttbar.rapidity,\n",
    "        \"pt_t1\": getattr(top[:, 0], \"pt\"),\n",
    "        \"pt_t2\": getattr(top[:, 1], \"pt\"),\n",
    "        \"dphi_ll\": getattr(lepton[:, 0], \"deltaphi\")(lepton[:, 1]) / np.pi,\n",
    "    })\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "df_truth = build_observables(nu[\"truth_top\"], nu[\"truth_lepton\"])\n",
    "df_reco_truthnu = build_observables(nu[\"plot_truth_top\"], nu[\"lepton\"])\n",
    "df_reco_prednu = build_observables(nu[\"top\"], nu[\"lepton\"])\n",
    "\n",
    "# Rename columns to avoid collisions\n",
    "df_truth = df_truth.add_suffix(\"_truth\")\n",
    "df_reco_truthnu = df_reco_truthnu.add_suffix(\"_reco_truthnu\")\n",
    "df_reco_prednu = df_reco_prednu.add_suffix(\"_reco_prednu\")\n",
    "\n",
    "# Combine into one DataFrame (all same length, aligned row by row)\n",
    "df_all = pd.concat([df_truth, df_reco_truthnu, df_reco_prednu], axis=1)\n",
    "# save the DataFrame for unfolding\n",
    "# df_all.to_csv(f\"{p_dir}/df_all.csv\", index=False)"
   ],
   "id": "7ec92a0d84f118d7",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T17:59:23.446106Z",
     "start_time": "2025-05-01T17:59:22.070436Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Unfolding\n",
    "from unfolding.unfold import main, hist_setup\n",
    "\n",
    "bin_edges = hist_setup()\n",
    "\n",
    "df_unfolded = main(df=df_all)"
   ],
   "id": "7107f9b15bc0f45d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: truthnu - Variable: dphi_ll - done\n",
      "Category: truthnu - Variable: pt_t1 - done\n",
      "Category: truthnu - Variable: pt_t2 - done\n",
      "Category: truthnu - Variable: pt_tt - done\n",
      "Category: truthnu - Variable: y_tt - done\n",
      "Category: prednu - Variable: dphi_ll - done\n",
      "Category: prednu - Variable: pt_t1 - done\n",
      "Category: prednu - Variable: pt_t2 - done\n",
      "Category: prednu - Variable: pt_tt - done\n",
      "Category: prednu - Variable: y_tt - done\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T19:43:19.266814Z",
     "start_time": "2025-05-01T19:43:17.478933Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def plot_uncertainty_with_ratio(\n",
    "        mtt_labels,\n",
    "        pt_labels,\n",
    "        xlabel,\n",
    "        methods,\n",
    "        ratio_baseline_name,\n",
    "        save_name=None,\n",
    "):\n",
    "    def pad_step_data(data):\n",
    "        data = np.array(data)\n",
    "        padded_data = np.concatenate([[data[0]], data, [data[-1]]])\n",
    "        padded_x = np.arange(-1, len(data) + 1)\n",
    "        return padded_x, padded_data\n",
    "\n",
    "    num_blocks = len(mtt_labels)\n",
    "    bins_per_block = len(pt_labels)\n",
    "    total_bins = num_blocks * bins_per_block\n",
    "    x = np.arange(total_bins)\n",
    "    x_labels = pt_labels * num_blocks\n",
    "\n",
    "    # Find baseline method\n",
    "    baseline_method = next((m for m in methods if m[\"name\"] == ratio_baseline_name), None)\n",
    "    if baseline_method is None:\n",
    "        raise ValueError(f\"Baseline method '{ratio_baseline_name}' not found in methods.\")\n",
    "\n",
    "    # Create figure\n",
    "    fig, (ax_top, ax_bot) = plt.subplots(\n",
    "        2, 1, figsize=(14, 7), sharex=True, height_ratios=[3, 1],\n",
    "        gridspec_kw={\"hspace\": 0.0}\n",
    "    )\n",
    "\n",
    "    # --- Top panel: Uncertainty ---\n",
    "    for method in methods:\n",
    "        x_pad, y_pad = pad_step_data(method[\"data\"])\n",
    "        ax_top.step(x_pad, y_pad, where='mid', label=method[\"name\"], color=method[\"color\"], linewidth=2)\n",
    "\n",
    "    for i in range(bins_per_block, total_bins, bins_per_block):\n",
    "        ax_top.axvline(i - 0.5, color='black', linestyle='--', lw=1)\n",
    "\n",
    "    max_val = max([max(m[\"data\"]) for m in methods])\n",
    "    for i, label in enumerate(mtt_labels):\n",
    "        center = i * bins_per_block + bins_per_block / 2 - 0.5\n",
    "        ax_top.text(center, max_val * 1.05, label, ha='center', fontsize=12)\n",
    "\n",
    "    ax_top.set_ylabel(\"Relative uncertainty\")\n",
    "    ax_top.set_ylim(1.0, max_val * 1.15)\n",
    "    ax_top.legend(\n",
    "        loc=\"upper right\",\n",
    "        bbox_to_anchor=(0.99, 1.12),\n",
    "        frameon=False,\n",
    "        ncol=len(methods),\n",
    "        fontsize=12,\n",
    "        handlelength=1.5,\n",
    "        columnspacing=1.0\n",
    "    )\n",
    "\n",
    "    # --- Bottom panel: Ratio ---\n",
    "    max_ratio = 1.0\n",
    "    for method in methods:\n",
    "        if method[\"name\"] == ratio_baseline_name:\n",
    "            continue\n",
    "        ratio = method[\"data\"] / baseline_method[\"data\"]\n",
    "\n",
    "        r_x_pad, r_y_pad = pad_step_data(ratio)\n",
    "        ax_bot.step(r_x_pad, r_y_pad, where='mid', color=method[\"color\"], linewidth=2)\n",
    "        # ax_bot.step(x, ratio, where='mid', color=method[\"color\"], linewidth=2)\n",
    "\n",
    "        for j, val in enumerate(ratio):\n",
    "            if val < 1.0:\n",
    "                ax_bot.plot(x[j], 1.05, marker='v', color=method[\"color\"], markersize=6)\n",
    "                print(f\"{method['name']} ratio < 1.0 at bin {j}: {val:.2f}\")\n",
    "\n",
    "        max_ratio = max(max_ratio, ratio.max())\n",
    "\n",
    "    ax_bot.axhline(1.0, color='black', lw=1)\n",
    "    ax_bot.set_ylabel(f\"Ratio to {ratio_baseline_name}\")\n",
    "    ax_bot.set_xticks(x)\n",
    "    ax_bot.set_xticklabels(x_labels, rotation=45, ha='right')\n",
    "    ax_bot.set_ylim(1.0, max(2.0, max_ratio * 1.05))\n",
    "\n",
    "    for i in range(bins_per_block, total_bins, bins_per_block):\n",
    "        ax_bot.axvline(i - 0.5, color='black', linestyle='--', lw=1)\n",
    "\n",
    "    ax_bot.set_xlabel(xlabel)\n",
    "    ax_bot.set_xlim(-0.5, total_bins - 0.5)\n",
    "    # set log scale for y-axis\n",
    "    # ax_bot.set_yscale('log')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if save_name:\n",
    "        if not os.path.exists(p_dir / \"uncertainty\"):\n",
    "            os.makedirs(p_dir / \"uncertainty\")\n",
    "        plt.savefig(p_dir / \"uncertainty\" / save_name)\n",
    "        plt.close()\n",
    "    else:\n",
    "        # Show the plot\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def build_16x16_response(\n",
    "        df,\n",
    "        mtt_truth_col,\n",
    "        mtt_reco_col,\n",
    "        var_truth_col,\n",
    "        var_reco_col,\n",
    "        mtt_bins,\n",
    "        var_bins\n",
    "):\n",
    "    nbins = len(var_bins) - 1\n",
    "    response = np.zeros((nbins * nbins, nbins * nbins))\n",
    "\n",
    "    for i in range(nbins):  # reco mtt bin\n",
    "        reco_mask = (df[mtt_reco_col] >= mtt_bins[i]) & (df[mtt_reco_col] < mtt_bins[i + 1])\n",
    "        for j in range(nbins):  # truth mtt bin\n",
    "            truth_mask = (df[mtt_truth_col] >= mtt_bins[j]) & (df[mtt_truth_col] < mtt_bins[j + 1])\n",
    "            mask = reco_mask & truth_mask\n",
    "            df_sel = df[mask]\n",
    "\n",
    "            h2d, _, _ = np.histogram2d(\n",
    "                df_sel[var_reco_col],\n",
    "                df_sel[var_truth_col],\n",
    "                bins=[var_bins, var_bins]\n",
    "            )\n",
    "\n",
    "            row_start = i * nbins\n",
    "            col_start = j * nbins\n",
    "            response[row_start:row_start + nbins, col_start:col_start + nbins] = h2d\n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "# Generalized plotting function\n",
    "def plot_block_response(\n",
    "        response,\n",
    "        var_labels,\n",
    "        mtt_labels,\n",
    "        title=None,\n",
    "        xlabel=\"Truth $m_{tt}$ bin\",\n",
    "        ylabel=\"Reco variable bin\",\n",
    "        save_name=None,\n",
    "):\n",
    "    fig, ax = plt.subplots(figsize=(7, 7))\n",
    "\n",
    "    truth_sums = response.sum(axis=0, keepdims=True)\n",
    "    normed = 100 * np.divide(response, truth_sums, where=truth_sums != 0)\n",
    "\n",
    "    im = ax.imshow(normed, origin='lower', cmap='Blues', vmin=0, vmax=100)\n",
    "\n",
    "    # Annotate matrix\n",
    "    for i in range(normed.shape[0]):\n",
    "        for j in range(normed.shape[1]):\n",
    "            val = normed[i, j]\n",
    "            if val > 1:\n",
    "                ax.text(j, i, f\"{val:.0f}\", ha='center', va='center', fontsize=7)\n",
    "\n",
    "    # Grid lines\n",
    "    block_size = len(var_labels)\n",
    "    for i in range(0, response.shape[0], block_size):\n",
    "        ax.axhline(i - 0.5, color='k', linestyle='--', lw=1)\n",
    "        ax.axvline(i - 0.5, color='k', linestyle='--', lw=1)\n",
    "    ax.axhline(response.shape[0] - 0.5, color='k', linestyle='--', lw=1)\n",
    "    ax.axvline(response.shape[1] - 0.5, color='k', linestyle='--', lw=1)\n",
    "\n",
    "    # X ticks: 1 per mtt bin (block center)\n",
    "    xticks = [i * block_size + block_size / 2 - 0.5 for i in range(len(mtt_labels))]\n",
    "    ax.set_xticks(xticks)\n",
    "    ax.set_xticklabels(mtt_labels, fontsize=10)\n",
    "\n",
    "    # Y ticks: 1 per var bin\n",
    "    yticks = list(range(block_size * len(mtt_labels)))\n",
    "    ytick_labels = var_labels * len(mtt_labels)\n",
    "    ax.set_yticks(yticks)\n",
    "    ax.set_yticklabels(ytick_labels, fontsize=8)\n",
    "\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_title(title)\n",
    "\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\"right\", size=\"3%\", pad=0.05)  # shrink width to 3%\n",
    "    cbar = plt.colorbar(im, cax=cax)\n",
    "    cbar.set_label(\"Migration [%]\", fontsize=9)\n",
    "\n",
    "    # Trace fraction\n",
    "    trace = np.trace(response)\n",
    "    total = response.sum()\n",
    "    trace_frac = trace / total if total > 0 else 0\n",
    "    ax.text(1.0, 1.02, f\"trace fraction = {trace_frac:.2f}\", transform=ax.transAxes,\n",
    "            ha='right', fontsize=10)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    # plt.show()\n",
    "    if save_name:\n",
    "        if not os.path.exists(p_dir / \"response\"):\n",
    "            os.makedirs(p_dir / \"response\")\n",
    "        plt.savefig(p_dir / \"response\" / save_name)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# Define bin edges\n",
    "bins_mtt = bin_edges[\"m_tt\"]\n",
    "mtt_labels = [\n",
    "    r\"$m_{t\\bar{t}} < 400$\",\n",
    "    r\"$400 < m_{t\\bar{t}} < 500$\",\n",
    "    r\"$500 < m_{t\\bar{t}} < 800$\",\n",
    "    r\"$m_{t\\bar{t}} \\geq 800$\"\n",
    "]\n",
    "common_labels = {\n",
    "    \"dphi_ll\": {\n",
    "        \"name\": r\"$\\Delta\\phi(\\ell^+,\\ell^-) / \\pi$ [rad/$\\pi$]\",\n",
    "        \"bins\": bin_edges[\"dphi_ll\"],\n",
    "        \"truth_col\": \"dphi_ll_truth\",\n",
    "        \"labels\": [\"0â€“0.25\", \"0.25â€“0.5\", \"0.5â€“0.75\", \"0.75â€“1.0\"]\n",
    "    },\n",
    "    \"pt_t1\": {\n",
    "        \"name\": r\"$p_T^t$ [GeV]\",\n",
    "        \"bins\": bin_edges[\"pt_t1\"],\n",
    "        \"truth_col\": \"pt_t1_truth\",\n",
    "        \"labels\": [\"<75\", \"75â€“125\", \"125â€“175\", \"â‰¥175\"]\n",
    "    },\n",
    "    \"pt_tt\": {\n",
    "        \"name\": r\"$p_{T}^{t\\bar{t}}$ [GeV]\",\n",
    "        \"bins\": bin_edges[\"pt_tt\"],\n",
    "        \"truth_col\": \"pt_tt_truth\",\n",
    "        \"labels\": [\"<70\", \"70â€“140\", \"140â€“200\", \"â‰¥200\"]\n",
    "    },\n",
    "    \"y_tt\": {\n",
    "        \"name\": r\"$y_{t\\bar{t}}$\",\n",
    "        \"bins\": bin_edges[\"y_tt\"],\n",
    "        \"truth_col\": \"y_tt_truth\",\n",
    "        \"labels\": [\"<â€“1\", \"â€“1â€“0\", \"0â€“1\", \">1\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "for scenario, s_name in zip([\"reco_truthnu\", \"reco_prednu\"], [\"Truth_Nu\", \"Pred_Nu\"]):\n",
    "    variable_configs = [\n",
    "        {\n",
    "            \"reco_col\": f\"dphi_ll_{scenario}\",\n",
    "            **common_labels[\"dphi_ll\"],\n",
    "        },\n",
    "        {\n",
    "            \"reco_col\": f\"pt_t1_{scenario}\",\n",
    "            **common_labels[\"pt_t1\"],\n",
    "        },\n",
    "        {\n",
    "            \"reco_col\": f\"pt_tt_{scenario}\",\n",
    "            **common_labels[\"pt_tt\"],\n",
    "        },\n",
    "        {\n",
    "            \"reco_col\": f\"y_tt_{scenario}\",\n",
    "            **common_labels[\"y_tt\"],\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # Build and plot all variables\n",
    "    for var in variable_configs:\n",
    "        response = build_16x16_response(\n",
    "            df_all,\n",
    "            mtt_truth_col=\"m_tt_truth\",\n",
    "            mtt_reco_col=\"m_tt_reco_prednu\",\n",
    "            var_truth_col=var[\"truth_col\"],\n",
    "            var_reco_col=var[\"reco_col\"],\n",
    "            mtt_bins=bins_mtt,\n",
    "            var_bins=var[\"bins\"]\n",
    "        )\n",
    "\n",
    "        plot_block_response(\n",
    "            response,\n",
    "            title=f\"EveNet: {s_name}\",\n",
    "            var_labels=var[\"labels\"],\n",
    "            mtt_labels=mtt_labels,\n",
    "            xlabel=f\"Detector-level {var['name']}\",\n",
    "            ylabel=f\"Parton-level {var['name']}\",\n",
    "            save_name=f\"{s_name}_{var['truth_col'].replace('_truth', '')}.pdf\"\n",
    "        )\n",
    "\n",
    "columns = list(range(16))\n",
    "paper_results = {\n",
    "    \"y_tt\": pd.DataFrame({\n",
    "        \"nu-weighting\": [2.9, 3.2, 3.0, 2.6, 2.9, 3.4, 3.1, 2.6, 2.7, 2.8, 2.9, 2.6, 2.4, 2.5, 2.6, 2.7],\n",
    "        \"Ellipse\": [3.5, 3.6, 3.2, 2.4, 2.2, 3.6, 3.5, 3.1, 3.6, 3.8, 4.1, 3.5, 3.1, 3.4, 3.6, 3.6],\n",
    "        \"nu2-flows\": [1.8, 1.9, 1.9, 1.8, 1.9, 2.1, 1.9, 1.8, 1.8, 1.8, 1.8, 1.7, 1.6, 1.6, 1.6, 1.7],\n",
    "        \"nu2-flows-pythia8\": [1.9, 1.9, 1.9, 1.8, 1.9, 2.1, 2.0, 1.8, 1.8, 1.8, 1.8, 1.7, 1.7, 1.6, 1.7, 1.8]\n",
    "    }, index=columns),\n",
    "    \"pt_tt\": pd.DataFrame({\n",
    "        \"nu-weighting\": [3.5, 2.6, 1.6, 2.1, 3.4, 3.0, 2.4, 2.3, 2.5, 2.7, 2.5, 2.2, 2.1, 2.2, 2.2, 2.3],\n",
    "        \"Ellipse\": [7.6, 5.3, 2.2, 3.7, 7.3, 5.7, 4.3, 4.1, 4.0, 4.7, 4.4, 3.8, 3.6, 3.3, 3.5, 3.8],\n",
    "        \"nu2-flows\": [1.9, 1.6, 1.2, 1.4, 2.0, 1.7, 1.5, 1.5, 1.6, 1.6, 1.6, 1.5, 1.5, 1.5, 1.5, 1.5],\n",
    "        \"nu2-flows-pythia8\": [2.0, 1.6, 1.2, 1.4, 2.0, 1.7, 1.5, 1.5, 1.7, 1.6, 1.6, 1.5, 1.5, 1.5, 1.5, 1.5]\n",
    "    }, index=columns),\n",
    "    \"pt_t1\": pd.DataFrame({\n",
    "        \"nu-weighting\": [3.1, 2.3, 1.7, 2.5, 3.2, 3.2, 2.8, 2.9, 2.8, 2.9, 2.9, 2.3, 2.2, 2.2, 2.3, 2.4],\n",
    "        \"Ellipse\": [4.8, 3.1, 2.5, 3.8, 4.9, 4.9, 3.8, 4.3, 4.0, 4.4, 4.9, 3.0, 3.5, 3.7, 3.6, 3.4],\n",
    "        \"nu2-flows\": [2.2, 1.9, 1.8, 2.1, 2.5, 2.4, 2.0, 2.2, 2.1, 2.0, 2.0, 1.7, 1.9, 1.9, 1.7, 1.6],\n",
    "        \"nu2-flows-pythia8\": [2.3, 1.9, 1.9, 2.2, 2.5, 2.4, 2.0, 2.3, 2.2, 2.1, 2.0, 1.7, 2.0, 2.0, 1.7, 1.6]\n",
    "    }, index=columns),\n",
    "    \"dphi_ll\": pd.DataFrame({\n",
    "        \"nu-weighting\": [2.0, 2.0, 1.5, 1.4, 1.9, 2.1, 2.0, 1.9, 1.9, 2.0, 2.2, 2.2, 2.0, 1.5, 1.6, 1.9],\n",
    "        \"Ellipse\": [2.2, 2.1, 1.5, 1.3, 1.8, 2.3, 2.4, 2.3, 2.3, 2.5, 2.8, 2.4, 1.7, 1.9, 2.4, 2.6],\n",
    "        \"nu2-flows\": [1.5, 1.5, 1.4, 1.4, 1.6, 1.6, 1.5, 1.5, 1.5, 1.5, 1.5, 1.3, 1.4, 1.5, 1.5, 1.5],\n",
    "        \"nu2-flows-pythia8\": [1.5, 1.5, 1.4, 1.4, 1.6, 1.6, 1.5, 1.5, 1.5, 1.5, 1.6, 1.5, 1.3, 1.4, 1.5, 1.5]\n",
    "    }, index=columns)\n",
    "}\n",
    "\n",
    "for var, var_cfg in common_labels.items():\n",
    "    truth = df_unfolded[f\"{var}_truthnu_unfold_error\"].values\n",
    "\n",
    "    methods = [\n",
    "        {\"name\": r\"EveNet\", \"color\": \"red\", \"data\": df_unfolded[f\"{var}_prednu_unfold_error\"] / truth},\n",
    "        {\"name\": r\"$\\nu^2$-Flows\", \"color\": \"blue\", \"data\": paper_results[var][\"nu2-flows\"].values},\n",
    "        # {\"name\": r\"$\\nu-2$-flow (P8)\", \"color\": \"green\", \"data\": paper_results[var][\"nu2-flows-pythia8\"].values},\n",
    "        {\"name\": r\"Ellipse\", \"color\": \"orange\", \"data\": paper_results[var][\"Ellipse\"].values},\n",
    "        {\"name\": r\"$\\nu$-weighting\", \"color\": \"purple\", \"data\": paper_results[var][\"nu-weighting\"].values}\n",
    "    ]\n",
    "\n",
    "    plot_uncertainty_with_ratio(\n",
    "        mtt_labels, var_cfg[\"labels\"], var_cfg['name'], methods,\n",
    "        ratio_baseline_name=r\"EveNet\",\n",
    "        save_name=f\"unfolded_{var}.pdf\"\n",
    "    )\n",
    "\n"
   ],
   "id": "159ec061131998aa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$\\nu^2$-Flows ratio < 1.0 at bin 11: 0.98\n",
      "$\\nu$-weighting ratio < 1.0 at bin 2: 0.96\n"
     ]
    }
   ],
   "execution_count": 75
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T17:59:34.056974Z",
     "start_time": "2025-05-01T17:59:27.336998Z"
    }
   },
   "cell_type": "code",
   "source": [
    "named_configs = {\n",
    "    \"neutrino\": {\n",
    "        \"variables\": [\"pt\", \"eta\", \"phi\"],\n",
    "        \"x_labels\": [r\"$p_T^{\\nu}$ [GeV]\", r\"$\\eta^{\\nu}$\", r\"$\\phi^{\\nu}$\"],\n",
    "        \"kin_range\": {\"pt\": (0, 350), \"eta\": (-np.pi * 1.5, np.pi * 1.5), \"phi\": (-np.pi, np.pi)},\n",
    "        \"labels\": [r\"$\\nu$ from $(top^+)$\", r\"$\\nu$ from $(top^-)$\"],\n",
    "        \"colors\": ['#5bb5ac', '#de526c'],\n",
    "        \"columns\": ['predict', 'target'],\n",
    "        \"log_y\": [True, False, False],\n",
    "    },\n",
    "    \"top\": {\n",
    "        \"variables\": [\"pt\", \"eta\", \"phi\", \"mass\"],\n",
    "        \"x_labels\": [r\"$p_T^{t}$ [GeV]\", r\"$\\eta^{t}$\", r\"$\\phi^{t}$\", r\"$mass^{t}$ [GeV]\"],\n",
    "        \"kin_range\": {\"pt\": (0, 600), \"eta\": (-np.pi * 1.5, np.pi * 1.5), \"phi\": (-np.pi, np.pi), \"mass\": (100, 240)},\n",
    "        \"labels\": [r\"$(top^+)$\", r\"$(top^-)$\"],\n",
    "        \"colors\": ['#5bb5ac', '#de526c'],\n",
    "        \"columns\": ['top', 'plot_truth_top'],\n",
    "        \"log_y\": [True, False, False, False],\n",
    "    },\n",
    "    \"W\": {\n",
    "        \"variables\": [\"pt\", \"eta\", \"phi\", \"mass\"],\n",
    "        \"x_labels\": [r\"$p_T^{W}$ [GeV]\", r\"$\\eta^{W}$\", r\"$\\phi^{W}$\", r\"$mass^{W}$ [GeV]\"],\n",
    "        \"kin_range\": {\"pt\": (0, 350), \"eta\": (-np.pi * 1.5, np.pi * 1.5), \"phi\": (-np.pi, np.pi), \"mass\": (40, 120)},\n",
    "        \"labels\": [r\"$(W^+)$\", r\"$(W^-)$\"],\n",
    "        \"colors\": ['#5bb5ac', '#de526c'],\n",
    "        \"columns\": ['W', 'plot_truth_W'],\n",
    "        \"log_y\": [True, False, False, False],\n",
    "    }\n",
    "}\n",
    "\n",
    "for particle, cfg in named_configs.items():\n",
    "\n",
    "    for i, var in enumerate(cfg[\"variables\"]):\n",
    "        fig, axs = plt.subplots(\n",
    "            3, 1, figsize=(10, 16),\n",
    "            gridspec_kw={'height_ratios': [3, 1, 2], 'hspace': 0.0},\n",
    "            sharex=True\n",
    "        )\n",
    "\n",
    "        plot_kinematics_comparison(\n",
    "            axs=axs,\n",
    "            kin=[getattr(nu[cfg['columns'][0]][..., 0], var), getattr(nu[cfg['columns'][0]][..., 1], var)],\n",
    "            truth_kin=[getattr(nu[cfg['columns'][1]][..., 0], var), getattr(nu[cfg['columns'][1]][..., 1], var)],\n",
    "            # kin=[\n",
    "            #     np.concatenate([\n",
    "            #         getattr(nu[cfg['columns'][0]][..., 0], var),\n",
    "            #         getattr(nu[cfg['columns'][0]][..., 1], var)\n",
    "            #     ], axis=0),\n",
    "            #     np.concatenate([\n",
    "            #         getattr(nu[cfg['columns'][0]][..., 0], var),\n",
    "            #         getattr(nu[cfg['columns'][0]][..., 1], var)\n",
    "            #     ], axis=0)\n",
    "            # ],\n",
    "            # truth_kin=[\n",
    "            #     np.concatenate([\n",
    "            #         getattr(nu[cfg['columns'][1]][..., 0], var),\n",
    "            #         getattr(nu[cfg['columns'][1]][..., 1], var)\n",
    "            #     ], axis=0),\n",
    "            #     np.concatenate([\n",
    "            #         getattr(nu[cfg['columns'][1]][..., 0], var),\n",
    "            #         getattr(nu[cfg['columns'][1]][..., 1], var)\n",
    "            #     ], axis=0)\n",
    "            # ],\n",
    "            bins=100,\n",
    "            kin_range=cfg[\"kin_range\"][var],\n",
    "            labels=cfg[\"labels\"],\n",
    "            colors=cfg[\"colors\"],\n",
    "            xlabel=cfg[\"x_labels\"][i],\n",
    "            normalize_col=cfg.get(\"normalize_col\", False),\n",
    "            log_z=cfg.get(\"log_z\", True),\n",
    "            log_y=cfg.get(\"log_y\", [False, False, False, False])[i],\n",
    "            c_percent=np.array([10, 100])\n",
    "        )\n",
    "\n",
    "        plt.tight_layout()\n",
    "        if not os.path.exists(p_dir / \"kinematics\"):\n",
    "            os.makedirs(p_dir / \"kinematics\")\n",
    "        plt.savefig(p_dir / \"kinematics\" / f\"{particle}_{var}.pdf\")\n",
    "        plt.close(fig)"
   ],
   "id": "6e664b18ea21d7cf",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/avencastmini/PycharmProjects/EveNet/downstreams/plotting/kinematic_comparison.py:51: UserWarning: Log scale: values of z <= 0 have been masked\n",
      "  ax.contourf(X, Y, Z, levels=levels, cmap=contour_colors[i], alpha=0.5, norm=mcolors.LogNorm())\n",
      "/Users/avencastmini/PycharmProjects/EveNet/downstreams/plotting/kinematic_comparison.py:51: UserWarning: Log scale: values of z <= 0 have been masked\n",
      "  ax.contourf(X, Y, Z, levels=levels, cmap=contour_colors[i], alpha=0.5, norm=mcolors.LogNorm())\n",
      "/Users/avencastmini/PycharmProjects/EveNet/downstreams/plotting/kinematic_comparison.py:51: UserWarning: Log scale: values of z <= 0 have been masked\n",
      "  ax.contourf(X, Y, Z, levels=levels, cmap=contour_colors[i], alpha=0.5, norm=mcolors.LogNorm())\n",
      "/Users/avencastmini/PycharmProjects/EveNet/downstreams/plotting/kinematic_comparison.py:51: UserWarning: Log scale: values of z <= 0 have been masked\n",
      "  ax.contourf(X, Y, Z, levels=levels, cmap=contour_colors[i], alpha=0.5, norm=mcolors.LogNorm())\n"
     ]
    }
   ],
   "execution_count": 7
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
