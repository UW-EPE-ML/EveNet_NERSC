Training:
  # Total plan epochs for optimizer decay
  total_epochs: 300
  # Trainer will stop at this epoch number
  epochs: 300

  model_checkpoint_save_path: "."
  model_checkpoint_load_path: null

  pretrain_model_load_path: null

  learning_rate: &lr 0.00005
  learning_rate_factor: &lr_factor 1.0
  learning_rate_warm_up_factor: &lr_warm 1.0
  weight_decay: &wd 0.001
  decoupled_weight_decay: &decouple_wd true

  diffusion_every_n_epochs: 20 # how often to run diffusion
  diffusion_every_n_steps: 1 # how often to run diffusion inside the valid epoch

  patience: 10 # early stopping patience


  Components:
    GlobalEmbedding:
      learning_rate: *lr
      optimizer_group: "body" # learning rate based on the first component
      optimizer_type: "adamw"
      warm_up: true
      weight_decay: *wd
      decoupled_weight_decay: *decouple_wd
      freeze:
        type: none # ['partial', 'full', 'none', 'random']
        partial_freeze_components: [ ]
        random_freeze_fraction: 0.0

    PET:
      learning_rate: *lr
      optimizer_group: "body"
      optimizer_type: "adamw"
      warm_up: true
      weight_decay: *wd
      decoupled_weight_decay: *decouple_wd
      freeze:
        type: none # ['partial', 'full', 'none', 'random']
        partial_freeze_components: [ ]
        random_freeze_fraction: 0.0

    ObjectEncoder:
      learning_rate: *lr
      optimizer_group: "object_encoder"
      optimizer_type: "adamw"
      warm_up: true
      weight_decay: *wd
      decoupled_weight_decay: *decouple_wd
      freeze:
        type: none # ['partial', 'full', 'none', 'random']
        partial_freeze_components: [ ]
        random_freeze_fraction: 0.0

    Classification:
      learning_rate: *lr
      optimizer_group: "classification"
      optimizer_type: "adamw"
      warm_up: true
      loss_scale: 1.0 # loss coefficient
      include: false # whether to build in network
      weight_decay: *wd
      decoupled_weight_decay: *decouple_wd
      freeze:
        type: none # ['partial', 'full', 'none', 'random']
        partial_freeze_components: [ ]
        random_freeze_fraction: 0.0

    Regression:
      learning_rate: *lr
      optimizer_group: "regression"
      optimizer_type: "adamw"
      warm_up: true
      loss_scale: 1.0 # loss coefficient
      include: false # whether to build in network
      weight_decay: *wd
      decoupled_weight_decay: *decouple_wd
      freeze:
        type: none # ['partial', 'full', 'none', 'random']
        partial_freeze_components: [ ]
        random_freeze_fraction: 0.0

    Assignment:
      learning_rate: *lr
      optimizer_group: "assignment"
      optimizer_type: "adamw"
      warm_up: true
      assignment_loss_scale: 1.0
      detection_loss_scale: 1.0
      focal_gamma: 0.0
      include: false # whether to build in network
      weight_decay: *wd
      decoupled_weight_decay: *decouple_wd
      freeze:
        type: none # ['partial', 'full', 'none', 'random']
        partial_freeze_components: [ ]
        random_freeze_fraction: 0.0

    GlobalGeneration:
      learning_rate: *lr
      optimizer_group: "generation"
      optimizer_type: "adamw"
      warm_up: true
      include: false # whether to build in network
      loss_scale: 1.0 # loss coefficient
      weight_decay: *wd
      decoupled_weight_decay: *decouple_wd
      diffusion_steps: 20
      freeze:
        type: none # ['partial', 'full', 'none', 'random']
        partial_freeze_components: [ ]
        random_freeze_fraction: 0.0

    ReconGeneration:
      learning_rate: *lr
      optimizer_group: "generation"
      optimizer_type: "lion"
      warm_up: true
      include: false # whether to build in network
      loss_scale: 1.0 # loss coefficient
      weight_decay: *wd
      decoupled_weight_decay: *decouple_wd
      diffusion_steps: 100
      freeze:
        type: none # ['partial', 'full', 'none', 'random']
        partial_freeze_components: [ ]
        random_freeze_fraction: 0.0
      use_generation_result: false # whether to use the generation result as input for the next step

    TruthGeneration:
      learning_rate: *lr
      optimizer_group: "generation"
      optimizer_type: "lion"
      warm_up: true
      include: false # whether to build in network
      loss_scale: 1.0 # loss coefficient
      weight_decay: *wd
      decoupled_weight_decay: *decouple_wd
      diffusion_steps: 100
      freeze:
        type: none # ['partial', 'full', 'none', 'random']
        partial_freeze_components: [ ]
        random_freeze_fraction: 0.0


  ProgressiveTraining:
    stages:
      - name: "full_training"
        epoch_ratio: 1.0
        transition_ratio: 0.0
        loss_weights:
          generation: [ 1.0, 1.0 ]
          classification: [ 1.0, 1.0 ]
          regression: [ 1.0, 1.0 ]
          assignment: [ 1.0, 1.0 ]


  EarlyStopping:
    patience: 20
    min_delta: 0.0
    monitor: "val/loss"
    mode: "min"
    verbose: true

  FAMO:
    turn_on: false
    detailed_loss: false
    detailed_loss_list:
      - classification
    logits_bound: 1.0
    lr: 0.025
#  GradientNorm:
#    alpha: 0.12
#    learning_rate: 0.0001

Dataset:
  dataset_limit: 1.0
  normalization_file: "/pscratch/sd/a/avencast/Event_Level_Analysis/Pretrain_Parquet/normalization_files/PreTrain_norm.pkl"
  val_split: [0.0, 0.2]

Metrics:
  Generation-Binning:
    num_vectors: [21, -1, 20]
    global-HT: [30, 0, 300]
    point cloud-eta: [20, -3, 3]
    point cloud-phi: [40, -4, 4]
    point cloud-ip3d: [60, -1, 2]
