platform:
  data_parquet_dir: "/pscratch/sd/t/tihsu/EventLevelPretrainedDataset/"
  number_of_workers: 1
  resources_per_worker: {
    "CPU": 16,
    "GPU": 1,
  }
  batch_size: 1024
  prefetch_batches: 2

wandb:
  project: "debug"
  entity: "ytchou97-university-of-washington"
  name: "seg-test"
  tags: [ "Pretrain", "NERSC", "Multi-Node", "135M", "Diffusion", "Vanilla" ]

options:
  default: options-seg.yaml

  Training:
    total_epochs: 100
    epochs: 100
    model_checkpoint_save_path: "/pscratch/sd/t/tihsu/EventLevelPretrainedDataset/"
    model_checkpoint_load_path: null
    pretrain_model_load_path: null

    diffusion_every_n_epochs: 2 # how often to run diffusion
    diffusion_every_n_steps: 1000 # how often to run diffusion inside the valid epoch

    learning_rate: &lr 0.00002
#    learning_rate: &lr 0.000045
    weight_decay: &wd 0.001
    optimizer_type_base:  &opt "lion"
    Components:
      GlobalEmbedding:
        learning_rate: *lr
        weight_decay: *wd
        optimizer_type: *opt
      PET:
        learning_rate: *lr
        weight_decay: *wd
        optimizer_type: *opt
      ObjectEncoder:
        learning_rate: *lr
        weight_decay: *wd
        optimizer_type: *opt
      Classification:
        include: true
        warm_up: true
        learning_rate: *lr
        weight_decay: *wd
        optimizer_type: *opt
      Regression:
        include: false
        learning_rate: *lr
        weight_decay: *wd
        optimizer_type: *opt
      Assignment:
        include: true
        warm_up: true
        learning_rate: *lr
        weight_decay: *wd
        optimizer_type: *opt
      GlobalGeneration:
        include: true
        warm_up: true
        learning_rate: *lr
        weight_decay: *wd
        optimizer_type: *opt
      ReconGeneration:
        include: true
        warm_up: true
        learning_rate: *lr
        weight_decay: *wd
        optimizer_type: *opt
      TruthGeneration:
        include: true
        warm_up: true
        learning_rate: *lr
        weight_decay: *wd
        optimizer_type: *opt
      Segmentation:
        include: true
        warm_up: true
        learning_rate: *lr
        weight_decay: *wd
        optimizer_type: *opt

    ProgressiveTraining:
      stages:
        - name: "full_training"
          epoch_ratio: 1.0
          transition_ratio: 0.1
          loss_weights:
            generation: [ 0.0, 0.0 ]
            classification: [ 1.0, 1.0 ]
            classification-noised: [ 0.0, 0.0 ]
            regression: [ 0.0, 0.0 ]
            assignment: [ 1.0, 1.0 ]
            segmentation: [1.0, 1.0]
          train_parameters:
            noise_prob: [1.0, 1.0]
            reco_attn_mask: [0.0, 0.0]
            ema_decay: [ 0.99, 0.999 ]

    FAMO:
      turn_on: false
      detailed_loss: false
      detailed_loss_list:
        - classification
        - generation-global
        - generation-event
        - generation-invisible
        - assignment
        - detection
      logits_bound: 0.5
      lr: 0.025

  Dataset:
    dataset_limit: 0.05
    normalization_file: "/pscratch/sd/t/tihsu/EventLevelPretrainedDataset//normalization.pt"
    val_split: [ 0.7, 1.0 ]

  Metrics:
    Generation-Binning:
      "global-HT": [ 50, 2, 8 ]

network:
  default: pretrain-small.yaml

  # overwrites
  # ...

event_info:
  default: multi_process_seg.yaml

  # overwrites
  # ...

resonance:
  default: standard_model.yaml

  # overwrites
  # ...
